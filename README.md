# boosting_lab
boosting_lab

## Work1
![avatar](Vehicle.png)

When n_tree grows to 50, the minimum error rate is basically obtained. At this time, with the growth of n_tree, the error rate is not decreasing but hovering around 0.24. I can see that as we increase the number of classifiers it doesn't necessarily decrease the error rate consistently, but it hovers around a limit, and if we add too many classifiers, the whole process takes longer The time, we need to balance the operation time and error rate to adjust n_tree.

## Work2
![avatar](Glass.png)

We can see that also in the Glass dataset, when n_tree grows to 50, we get the lowest error rate -0.15 or so. We can still get the conclusion of the previous experiment.

## Work3
